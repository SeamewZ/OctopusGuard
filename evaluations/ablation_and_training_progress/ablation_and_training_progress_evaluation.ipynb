{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5135ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_path = \"OctopusGuard/data/experiment_address.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "df[\"scam\"] = 1\n",
    "df.loc[df.index[-30:], \"scam\"] = 0\n",
    "\n",
    "models = [\"0_steps\", \"74_steps\", \"148_steps\", \"222_steps\", \"296_steps\"]\n",
    "tasks = [\"Kline_scam\", \"Tx_scam\", \"code_scam\", \"multimodal_scam\"]\n",
    "\n",
    "for model in models:\n",
    "    for task in tasks:\n",
    "        df[f\"{model}_{task}\"] = None  \n",
    "\n",
    "output_path = \"OctopusGuard/evaluations/ablation_and_training_progress/stepwise_template.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"successï¼š{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "API_KEY = \"sk-\" \n",
    "\n",
    "file_paths = {\n",
    "    \"log_file\": \"OctopusGuard/evaluations/ablation_and_training_progress/logs/analysis_log_checkpoint-74.txt\",\n",
    "    \"gt_json\": \"OctopusGuard/evaluations/ablation_and_training_progress/test_multimodal_data.json\",\n",
    "    \"template_csv\": \"OctopusGuard/evaluations/ablation_and_training_progress/stepwise_template.csv\",\n",
    "}\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "api_cache = {}\n",
    "def deepseek_judge_match(gt: str, slither_output: str) -> str:\n",
    "    cache_key = (gt, slither_output)\n",
    "    if cache_key in api_cache:\n",
    "        return api_cache[cache_key]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "The following is the Ground Truth (human-labeled vulnerability description):\n",
    "{gt}\n",
    "\n",
    "And here is the vulnerability analysis output by the OctopusGuard tool:\n",
    "{slither_output}\n",
    "\n",
    "As a blockchain security expert, please evaluate the following:\n",
    "1. Does the OctopusGuard output cover all the core issues in the Ground Truth? Summarize your judgment in one sentence (Match, Partial Match, No Match).\n",
    "2. Give a similarity score between 0 and 100 indicating how well OctopusGuard's output matches the Ground Truth. Please use the format: `Score: XX`\n",
    "\"\"\"\n",
    "    for attempt in range(3): \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "                max_tokens=256,\n",
    "                stream=False\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            api_cache[cache_key] = result \n",
    "            print(result)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"  [API Error] Attempt {attempt + 1} failed: {e}. Retrying in 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    print(f\"  [API Error] All attempts failed for GT: '{gt[:50]}...' and Output: '{slither_output[:50]}...'\")\n",
    "    return \"Score: 0\" \n",
    "\n",
    "\n",
    "def parse_model_log(log_path: str) -> dict:\n",
    "    print(f\"Parsing model log file: {log_path}\")\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    results = {}\n",
    "    blocks = re.split(r'==================== Contract Address: ', content)\n",
    "    \n",
    "    for block in tqdm(blocks, desc=\"Parsing Log Blocks\"):\n",
    "        if not block.strip():\n",
    "            continue\n",
    "        \n",
    "        addr_match = re.match(r'(0x[a-fA-F0-9]{40})', block)\n",
    "        if not addr_match:\n",
    "            continue\n",
    "        address = addr_match.group(1).lower()\n",
    "\n",
    "        patterns = {\n",
    "            'kline': r\"ðŸ–¼ï¸ Analyzing token price chart image.*?A:(.*?)(?=ðŸ“Š Analyzing transaction data)\",\n",
    "            'tx': r\"ðŸ“Š Analyzing transaction data.*?A:(.*?)(?=ðŸ” Analyzing smart contract code)\",\n",
    "            'code': r\"ðŸ“ Contract Analysis Dialogue Log:.*?A:(.*?)(?=ðŸ§  Final Assessment)\",\n",
    "            'multimodal': r\"ðŸ§  Final Assessment:(.*?)(?======================= ANALYSIS COMPLETE)\"\n",
    "        }\n",
    "        \n",
    "        parsed_data = {}\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, block, re.DOTALL | re.IGNORECASE)\n",
    "            if match:\n",
    "                parsed_data[key] = match.group(1).strip()\n",
    "            else:\n",
    "                parsed_data[key] = \"\" \n",
    "        \n",
    "        results[address] = parsed_data\n",
    "    return results\n",
    "\n",
    "def load_ground_truth(json_path: str) -> list:\n",
    "    print(f\"Loading ground truth from: {json_path}\")\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    gt_list = []\n",
    "    for i in range(0, len(data), 6):\n",
    "        group = data[i:i+6]\n",
    "        if len(group) == 6:\n",
    "            gt_list.append({\n",
    "                'kline_gt': group[0]['completion'],\n",
    "                'tx_gt': group[1]['completion'],\n",
    "                'code_gt': group[4]['completion'],\n",
    "            })\n",
    "    return gt_list\n",
    "\n",
    "def main():\n",
    "    \n",
    "    df = pd.read_csv(file_paths[\"template_csv\"])\n",
    "    df['contract_address'] = df['contract_address'].str.lower()\n",
    "    \n",
    "    model_outputs = parse_model_log(file_paths[\"log_file\"])\n",
    "    ground_truths = load_ground_truth(file_paths[\"gt_json\"])\n",
    "    \n",
    "    if len(df) != len(ground_truths) or len(df) != len(model_outputs):\n",
    "        print(f\"Warning: Data length mismatch!\")\n",
    "        print(f\"CSV rows: {len(df)}, GT entries: {len(ground_truths)}, Logged addresses: {len(model_outputs)}\")\n",
    "    \n",
    "    address_list = df['contract_address'].tolist()\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Contracts\"):\n",
    "        address = row['contract_address']\n",
    "        \n",
    "        gt_scam_label = row['scam'] \n",
    "        \n",
    "        if i >= len(ground_truths):\n",
    "            print(f\"Warning: No ground truth found for index {i}, address {address}. Skipping.\")\n",
    "            continue\n",
    "        gt_data = ground_truths[i]\n",
    "\n",
    "        if address not in model_outputs:\n",
    "            print(f\"Warning: No model output found for address {address}. Skipping.\")\n",
    "            continue\n",
    "        model_output = model_outputs[address]\n",
    "\n",
    "        print('11---------------------')\n",
    "        print(model_output.get('kline', '').lower())\n",
    "        print('11---------------------')\n",
    "        model_predicts_scam_kline = \"yes\" in model_output.get('kline', '').lower()\n",
    "        is_correct_kline = (model_predicts_scam_kline)\n",
    "        print('12---------------------')\n",
    "        print(is_correct_kline)\n",
    "        print('12---------------------')\n",
    "        df.loc[i, '74_steps_Kline_scam'] = 1 if is_correct_kline else 0\n",
    "\n",
    "        print('21---------------------')\n",
    "        print(model_output.get('tx', '').lower())\n",
    "        print('21---------------------')\n",
    "        model_predicts_scam_tx = \"yes\" in model_output.get('tx', '').lower()\n",
    "        is_correct_tx = (model_predicts_scam_tx)\n",
    "        print('22---------------------')\n",
    "        print(is_correct_tx)\n",
    "        print('22---------------------')\n",
    "        df.loc[i, '74_steps_Tx_scam'] = 1 if is_correct_tx else 0\n",
    "        \n",
    "        print('31---------------------')\n",
    "        print(model_output.get('multimodal', '').lower())\n",
    "        print('31---------------------')\n",
    "        model_predicts_scam_multi = \"yes\" in model_output.get('multimodal', '').lower()\n",
    "        is_correct_multi = (model_predicts_scam_multi)\n",
    "        print('32---------------------')\n",
    "        print(is_correct_multi)\n",
    "        print('32---------------------')\n",
    "        df.loc[i, '74_steps_multimodal_scam'] = 1 if is_correct_multi else 0\n",
    "\n",
    "        gt_code = gt_data['code_gt']\n",
    "        model_code = model_output.get('code', 'No output found.')\n",
    "        print('41---------------------')\n",
    "        print(model_code)\n",
    "        print('41---------------------')\n",
    "        \n",
    "        api_response = deepseek_judge_match(gt_code, model_code)\n",
    "        \n",
    "        score_match = re.search(r'Score:\\s*(\\d+)', api_response, re.IGNORECASE)\n",
    "        score = int(score_match.group(1)) if score_match else 0\n",
    "        \n",
    "        is_match = score >= 50\n",
    "        print('42---------------------')\n",
    "        print(is_match)\n",
    "        print('42---------------------')\n",
    "        if i < 270:\n",
    "            df.loc[i, '74_steps_code_scam'] = 1 if is_match else 0\n",
    "        else:\n",
    "            df.loc[i, '74_steps_code_scam'] = 0 if is_match else 1\n",
    "\n",
    "    df.to_csv(file_paths[\"template_csv\"], index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nAnalysis complete! Results saved to: {file_paths['template_csv']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "API_KEY = \"sk-\" \n",
    "\n",
    "file_paths = {\n",
    "    \"log_file\": \"OctopusGuard/evaluations/ablation_and_training_progress/logs/analysis_log_checkpoint-148.txt\",\n",
    "    \"gt_json\": \"OctopusGuard/evaluations/ablation_and_training_progress/test_multimodal_data.json\",\n",
    "    \"template_csv\": \"OctopusGuard/evaluations/ablation_and_training_progress/stepwise_template.csv\",\n",
    "}\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "api_cache = {}\n",
    "def deepseek_judge_match(gt: str, slither_output: str) -> str:\n",
    "    cache_key = (gt, slither_output)\n",
    "    if cache_key in api_cache:\n",
    "        return api_cache[cache_key]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "The following is the Ground Truth (human-labeled vulnerability description):\n",
    "{gt}\n",
    "\n",
    "And here is the vulnerability analysis output by the OctopusGuard tool:\n",
    "{slither_output}\n",
    "\n",
    "As a blockchain security expert, please evaluate the following:\n",
    "1. Does the OctopusGuard output cover all the core issues in the Ground Truth? Summarize your judgment in one sentence (Match, Partial Match, No Match).\n",
    "2. Give a similarity score between 0 and 100 indicating how well OctopusGuard's output matches the Ground Truth. Please use the format: `Score: XX`\n",
    "\"\"\"\n",
    "    for attempt in range(3): \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "                max_tokens=256,\n",
    "                stream=False\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            api_cache[cache_key] = result \n",
    "            print(result)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"  [API Error] Attempt {attempt + 1} failed: {e}. Retrying in 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    print(f\"  [API Error] All attempts failed for GT: '{gt[:50]}...' and Output: '{slither_output[:50]}...'\")\n",
    "    return \"Score: 0\" \n",
    "\n",
    "\n",
    "def parse_model_log(log_path: str) -> dict:\n",
    "    print(f\"Parsing model log file: {log_path}\")\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    results = {}\n",
    "    blocks = re.split(r'==================== Contract Address: ', content)\n",
    "    \n",
    "    for block in tqdm(blocks, desc=\"Parsing Log Blocks\"):\n",
    "        if not block.strip():\n",
    "            continue\n",
    "        \n",
    "        addr_match = re.match(r'(0x[a-fA-F0-9]{40})', block)\n",
    "        if not addr_match:\n",
    "            continue\n",
    "        address = addr_match.group(1).lower()\n",
    "\n",
    "        patterns = {\n",
    "            'kline': r\"ðŸ–¼ï¸ Analyzing token price chart image.*?A:(.*?)(?=ðŸ“Š Analyzing transaction data)\",\n",
    "            'tx': r\"ðŸ“Š Analyzing transaction data.*?A:(.*?)(?=ðŸ” Analyzing smart contract code)\",\n",
    "            'code': r\"ðŸ“ Contract Analysis Dialogue Log:.*?A:(.*?)(?=ðŸ§  Final Assessment)\",\n",
    "            'multimodal': r\"ðŸ§  Final Assessment:(.*?)(?======================= ANALYSIS COMPLETE)\"\n",
    "        }\n",
    "        \n",
    "        parsed_data = {}\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, block, re.DOTALL | re.IGNORECASE)\n",
    "            if match:\n",
    "                parsed_data[key] = match.group(1).strip()\n",
    "            else:\n",
    "                parsed_data[key] = \"\" \n",
    "        \n",
    "        results[address] = parsed_data\n",
    "    return results\n",
    "\n",
    "def load_ground_truth(json_path: str) -> list:\n",
    "    print(f\"Loading ground truth from: {json_path}\")\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    gt_list = []\n",
    "    for i in range(0, len(data), 6):\n",
    "        group = data[i:i+6]\n",
    "        if len(group) == 6:\n",
    "            gt_list.append({\n",
    "                'kline_gt': group[0]['completion'],\n",
    "                'tx_gt': group[1]['completion'],\n",
    "                'code_gt': group[4]['completion'],\n",
    "            })\n",
    "    return gt_list\n",
    "\n",
    "def main():\n",
    "    \n",
    "    df = pd.read_csv(file_paths[\"template_csv\"])\n",
    "    df['contract_address'] = df['contract_address'].str.lower()\n",
    "    \n",
    "    model_outputs = parse_model_log(file_paths[\"log_file\"])\n",
    "    ground_truths = load_ground_truth(file_paths[\"gt_json\"])\n",
    "    \n",
    "    if len(df) != len(ground_truths) or len(df) != len(model_outputs):\n",
    "        print(f\"Warning: Data length mismatch!\")\n",
    "        print(f\"CSV rows: {len(df)}, GT entries: {len(ground_truths)}, Logged addresses: {len(model_outputs)}\")\n",
    "    \n",
    "    address_list = df['contract_address'].tolist()\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Contracts\"):\n",
    "        address = row['contract_address']\n",
    "        \n",
    "        gt_scam_label = row['scam'] \n",
    "        \n",
    "        if i >= len(ground_truths):\n",
    "            print(f\"Warning: No ground truth found for index {i}, address {address}. Skipping.\")\n",
    "            continue\n",
    "        gt_data = ground_truths[i]\n",
    "\n",
    "        if address not in model_outputs:\n",
    "            print(f\"Warning: No model output found for address {address}. Skipping.\")\n",
    "            continue\n",
    "        model_output = model_outputs[address]\n",
    "\n",
    "        print('11---------------------')\n",
    "        print(model_output.get('kline', '').lower())\n",
    "        print('11---------------------')\n",
    "        model_predicts_scam_kline = \"yes\" in model_output.get('kline', '').lower()\n",
    "        is_correct_kline = (model_predicts_scam_kline)\n",
    "        print('12---------------------')\n",
    "        print(is_correct_kline)\n",
    "        print('12---------------------')\n",
    "        df.loc[i, '148_steps_Kline_scam'] = 1 if is_correct_kline else 0\n",
    "\n",
    "        print('21---------------------')\n",
    "        print(model_output.get('tx', '').lower())\n",
    "        print('21---------------------')\n",
    "        model_predicts_scam_tx = \"yes\" in model_output.get('tx', '').lower()\n",
    "        is_correct_tx = (model_predicts_scam_tx)\n",
    "        print('22---------------------')\n",
    "        print(is_correct_tx)\n",
    "        print('22---------------------')\n",
    "        df.loc[i, '148_steps_Tx_scam'] = 1 if is_correct_tx else 0\n",
    "        \n",
    "        print('31---------------------')\n",
    "        print(model_output.get('multimodal', '').lower())\n",
    "        print('31---------------------')\n",
    "        model_predicts_scam_multi = \"yes\" in model_output.get('multimodal', '').lower()\n",
    "        is_correct_multi = (model_predicts_scam_multi)\n",
    "        print('32---------------------')\n",
    "        print(is_correct_multi)\n",
    "        print('32---------------------')\n",
    "        df.loc[i, '148_steps_multimodal_scam'] = 1 if is_correct_multi else 0\n",
    "\n",
    "        gt_code = gt_data['code_gt']\n",
    "        model_code = model_output.get('code', 'No output found.')\n",
    "        print('41---------------------')\n",
    "        print(model_code)\n",
    "        print('41---------------------')\n",
    "        \n",
    "        api_response = deepseek_judge_match(gt_code, model_code)\n",
    "        \n",
    "        score_match = re.search(r'Score:\\s*(\\d+)', api_response, re.IGNORECASE)\n",
    "        score = int(score_match.group(1)) if score_match else 0\n",
    "        \n",
    "        is_match = score >= 50\n",
    "        print('42---------------------')\n",
    "        print(is_match)\n",
    "        print('42---------------------')\n",
    "        if i < 270:\n",
    "            df.loc[i, '148_steps_code_scam'] = 1 if is_match else 0\n",
    "        else:\n",
    "            df.loc[i, '148_steps_code_scam'] = 0 if is_match else 1\n",
    "\n",
    "    df.to_csv(file_paths[\"template_csv\"], index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nAnalysis complete! Results saved to: {file_paths['template_csv']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "API_KEY = \"sk-\" \n",
    "\n",
    "file_paths = {\n",
    "    \"log_file\": \"OctopusGuard/evaluations/ablation_and_training_progress/logs/analysis_log_checkpoint-222.txt\",\n",
    "    \"gt_json\": \"OctopusGuard/evaluations/ablation_and_training_progress/test_multimodal_data.json\",\n",
    "    \"template_csv\": \"OctopusGuard/evaluations/ablation_and_training_progress/stepwise_template.csv\",\n",
    "}\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "api_cache = {}\n",
    "def deepseek_judge_match(gt: str, slither_output: str) -> str:\n",
    "    cache_key = (gt, slither_output)\n",
    "    if cache_key in api_cache:\n",
    "        return api_cache[cache_key]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "The following is the Ground Truth (human-labeled vulnerability description):\n",
    "{gt}\n",
    "\n",
    "And here is the vulnerability analysis output by the OctopusGuard tool:\n",
    "{slither_output}\n",
    "\n",
    "As a blockchain security expert, please evaluate the following:\n",
    "1. Does the OctopusGuard output cover all the core issues in the Ground Truth? Summarize your judgment in one sentence (Match, Partial Match, No Match).\n",
    "2. Give a similarity score between 0 and 100 indicating how well OctopusGuard's output matches the Ground Truth. Please use the format: `Score: XX`\n",
    "\"\"\"\n",
    "    for attempt in range(3): \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "                max_tokens=256,\n",
    "                stream=False\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            api_cache[cache_key] = result \n",
    "            print(result)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"  [API Error] Attempt {attempt + 1} failed: {e}. Retrying in 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    print(f\"  [API Error] All attempts failed for GT: '{gt[:50]}...' and Output: '{slither_output[:50]}...'\")\n",
    "    return \"Score: 0\" \n",
    "\n",
    "\n",
    "def parse_model_log(log_path: str) -> dict:\n",
    "    print(f\"Parsing model log file: {log_path}\")\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    results = {}\n",
    "    blocks = re.split(r'==================== Contract Address: ', content)\n",
    "    \n",
    "    for block in tqdm(blocks, desc=\"Parsing Log Blocks\"):\n",
    "        if not block.strip():\n",
    "            continue\n",
    "        \n",
    "        addr_match = re.match(r'(0x[a-fA-F0-9]{40})', block)\n",
    "        if not addr_match:\n",
    "            continue\n",
    "        address = addr_match.group(1).lower()\n",
    "\n",
    "        patterns = {\n",
    "            'kline': r\"ðŸ–¼ï¸ Analyzing token price chart image.*?A:(.*?)(?=ðŸ“Š Analyzing transaction data)\",\n",
    "            'tx': r\"ðŸ“Š Analyzing transaction data.*?A:(.*?)(?=ðŸ” Analyzing smart contract code)\",\n",
    "            'code': r\"ðŸ“ Contract Analysis Dialogue Log:.*?A:(.*?)(?=ðŸ§  Final Assessment)\",\n",
    "            'multimodal': r\"ðŸ§  Final Assessment:(.*?)(?======================= ANALYSIS COMPLETE)\"\n",
    "        }\n",
    "        \n",
    "        parsed_data = {}\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, block, re.DOTALL | re.IGNORECASE)\n",
    "            if match:\n",
    "                parsed_data[key] = match.group(1).strip()\n",
    "            else:\n",
    "                parsed_data[key] = \"\" \n",
    "        \n",
    "        results[address] = parsed_data\n",
    "    return results\n",
    "\n",
    "def load_ground_truth(json_path: str) -> list:\n",
    "    print(f\"Loading ground truth from: {json_path}\")\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    gt_list = []\n",
    "    for i in range(0, len(data), 6):\n",
    "        group = data[i:i+6]\n",
    "        if len(group) == 6:\n",
    "            gt_list.append({\n",
    "                'kline_gt': group[0]['completion'],\n",
    "                'tx_gt': group[1]['completion'],\n",
    "                'code_gt': group[4]['completion'],\n",
    "            })\n",
    "    return gt_list\n",
    "\n",
    "def main():\n",
    "    \n",
    "    df = pd.read_csv(file_paths[\"template_csv\"])\n",
    "    df['contract_address'] = df['contract_address'].str.lower()\n",
    "    \n",
    "    model_outputs = parse_model_log(file_paths[\"log_file\"])\n",
    "    ground_truths = load_ground_truth(file_paths[\"gt_json\"])\n",
    "    \n",
    "    if len(df) != len(ground_truths) or len(df) != len(model_outputs):\n",
    "        print(f\"Warning: Data length mismatch!\")\n",
    "        print(f\"CSV rows: {len(df)}, GT entries: {len(ground_truths)}, Logged addresses: {len(model_outputs)}\")\n",
    "    \n",
    "    address_list = df['contract_address'].tolist()\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Contracts\"):\n",
    "        address = row['contract_address']\n",
    "        \n",
    "        gt_scam_label = row['scam'] \n",
    "        \n",
    "        if i >= len(ground_truths):\n",
    "            print(f\"Warning: No ground truth found for index {i}, address {address}. Skipping.\")\n",
    "            continue\n",
    "        gt_data = ground_truths[i]\n",
    "\n",
    "        if address not in model_outputs:\n",
    "            print(f\"Warning: No model output found for address {address}. Skipping.\")\n",
    "            continue\n",
    "        model_output = model_outputs[address]\n",
    "\n",
    "        print('11---------------------')\n",
    "        print(model_output.get('kline', '').lower())\n",
    "        print('11---------------------')\n",
    "        model_predicts_scam_kline = \"yes\" in model_output.get('kline', '').lower()\n",
    "        is_correct_kline = (model_predicts_scam_kline)\n",
    "        print('12---------------------')\n",
    "        print(is_correct_kline)\n",
    "        print('12---------------------')\n",
    "        df.loc[i, '222_steps_Kline_scam'] = 1 if is_correct_kline else 0\n",
    "\n",
    "        print('21---------------------')\n",
    "        print(model_output.get('tx', '').lower())\n",
    "        print('21---------------------')\n",
    "        model_predicts_scam_tx = \"yes\" in model_output.get('tx', '').lower()\n",
    "        is_correct_tx = (model_predicts_scam_tx)\n",
    "        print('22---------------------')\n",
    "        print(is_correct_tx)\n",
    "        print('22---------------------')\n",
    "        df.loc[i, '222_steps_Tx_scam'] = 1 if is_correct_tx else 0\n",
    "        \n",
    "        print('31---------------------')\n",
    "        print(model_output.get('multimodal', '').lower())\n",
    "        print('31---------------------')\n",
    "        model_predicts_scam_multi = \"yes\" in model_output.get('multimodal', '').lower()\n",
    "        is_correct_multi = (model_predicts_scam_multi)\n",
    "        print('32---------------------')\n",
    "        print(is_correct_multi)\n",
    "        print('32---------------------')\n",
    "        df.loc[i, '222_steps_multimodal_scam'] = 1 if is_correct_multi else 0\n",
    "\n",
    "        gt_code = gt_data['code_gt']\n",
    "        model_code = model_output.get('code', 'No output found.')\n",
    "        print('41---------------------')\n",
    "        print(model_code)\n",
    "        print('41---------------------')\n",
    "        \n",
    "        api_response = deepseek_judge_match(gt_code, model_code)\n",
    "        \n",
    "        score_match = re.search(r'Score:\\s*(\\d+)', api_response, re.IGNORECASE)\n",
    "        score = int(score_match.group(1)) if score_match else 0\n",
    "        \n",
    "        is_match = score >= 50\n",
    "        print('42---------------------')\n",
    "        print(is_match)\n",
    "        print('42---------------------')\n",
    "        if i < 270:\n",
    "            df.loc[i, '222_steps_code_scam'] = 1 if is_match else 0\n",
    "        else:\n",
    "            df.loc[i, '222_steps_code_scam'] = 0 if is_match else 1\n",
    "\n",
    "    df.to_csv(file_paths[\"template_csv\"], index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nAnalysis complete! Results saved to: {file_paths['template_csv']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e03dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "API_KEY = \"sk-\" \n",
    "\n",
    "file_paths = {\n",
    "    \"log_file\": \"OctopusGuard/evaluations/ablation_and_training_progress/logs/analysis_log_checkpoint-296.txt\",\n",
    "    \"gt_json\": \"OctopusGuard/evaluations/ablation_and_training_progress/test_multimodal_data.json\",\n",
    "    \"template_csv\": \"OctopusGuard/evaluations/ablation_and_training_progress/stepwise_template.csv\",\n",
    "}\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "api_cache = {}\n",
    "def deepseek_judge_match(gt: str, slither_output: str) -> str:\n",
    "    cache_key = (gt, slither_output)\n",
    "    if cache_key in api_cache:\n",
    "        return api_cache[cache_key]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "The following is the Ground Truth (human-labeled vulnerability description):\n",
    "{gt}\n",
    "\n",
    "And here is the vulnerability analysis output by the OctopusGuard tool:\n",
    "{slither_output}\n",
    "\n",
    "As a blockchain security expert, please evaluate the following:\n",
    "1. Does the OctopusGuard output cover all the core issues in the Ground Truth? Summarize your judgment in one sentence (Match, Partial Match, No Match).\n",
    "2. Give a similarity score between 0 and 100 indicating how well OctopusGuard's output matches the Ground Truth. Please use the format: `Score: XX`\n",
    "\"\"\"\n",
    "    for attempt in range(3): \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "                max_tokens=256,\n",
    "                stream=False\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            api_cache[cache_key] = result \n",
    "            print(result)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"  [API Error] Attempt {attempt + 1} failed: {e}. Retrying in 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    print(f\"  [API Error] All attempts failed for GT: '{gt[:50]}...' and Output: '{slither_output[:50]}...'\")\n",
    "    return \"Score: 0\" \n",
    "\n",
    "\n",
    "def parse_model_log(log_path: str) -> dict:\n",
    "    print(f\"Parsing model log file: {log_path}\")\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    results = {}\n",
    "    blocks = re.split(r'==================== Contract Address: ', content)\n",
    "    \n",
    "    for block in tqdm(blocks, desc=\"Parsing Log Blocks\"):\n",
    "        if not block.strip():\n",
    "            continue\n",
    "        \n",
    "        addr_match = re.match(r'(0x[a-fA-F0-9]{40})', block)\n",
    "        if not addr_match:\n",
    "            continue\n",
    "        address = addr_match.group(1).lower()\n",
    "\n",
    "        patterns = {\n",
    "            'kline': r\"ðŸ–¼ï¸ Analyzing token price chart image.*?A:(.*?)(?=ðŸ“Š Analyzing transaction data)\",\n",
    "            'tx': r\"ðŸ“Š Analyzing transaction data.*?A:(.*?)(?=ðŸ” Analyzing smart contract code)\",\n",
    "            'code': r\"ðŸ“ Contract Analysis Dialogue Log:.*?A:(.*?)(?=ðŸ§  Final Assessment)\",\n",
    "            'multimodal': r\"ðŸ§  Final Assessment:(.*?)(?======================= ANALYSIS COMPLETE)\"\n",
    "        }\n",
    "        \n",
    "        parsed_data = {}\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, block, re.DOTALL | re.IGNORECASE)\n",
    "            if match:\n",
    "                parsed_data[key] = match.group(1).strip()\n",
    "            else:\n",
    "                parsed_data[key] = \"\" \n",
    "        \n",
    "        results[address] = parsed_data\n",
    "    return results\n",
    "\n",
    "def load_ground_truth(json_path: str) -> list:\n",
    "    print(f\"Loading ground truth from: {json_path}\")\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    gt_list = []\n",
    "    for i in range(0, len(data), 6):\n",
    "        group = data[i:i+6]\n",
    "        if len(group) == 6:\n",
    "            gt_list.append({\n",
    "                'kline_gt': group[0]['completion'],\n",
    "                'tx_gt': group[1]['completion'],\n",
    "                'code_gt': group[4]['completion'],\n",
    "            })\n",
    "    return gt_list\n",
    "\n",
    "def main():\n",
    "    \n",
    "    df = pd.read_csv(file_paths[\"template_csv\"])\n",
    "    df['contract_address'] = df['contract_address'].str.lower()\n",
    "    \n",
    "    model_outputs = parse_model_log(file_paths[\"log_file\"])\n",
    "    ground_truths = load_ground_truth(file_paths[\"gt_json\"])\n",
    "    \n",
    "    if len(df) != len(ground_truths) or len(df) != len(model_outputs):\n",
    "        print(f\"Warning: Data length mismatch!\")\n",
    "        print(f\"CSV rows: {len(df)}, GT entries: {len(ground_truths)}, Logged addresses: {len(model_outputs)}\")\n",
    "    \n",
    "    address_list = df['contract_address'].tolist()\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Contracts\"):\n",
    "        address = row['contract_address']\n",
    "        \n",
    "        gt_scam_label = row['scam'] \n",
    "        \n",
    "        if i >= len(ground_truths):\n",
    "            print(f\"Warning: No ground truth found for index {i}, address {address}. Skipping.\")\n",
    "            continue\n",
    "        gt_data = ground_truths[i]\n",
    "\n",
    "        if address not in model_outputs:\n",
    "            print(f\"Warning: No model output found for address {address}. Skipping.\")\n",
    "            continue\n",
    "        model_output = model_outputs[address]\n",
    "\n",
    "        print('11---------------------')\n",
    "        print(model_output.get('kline', '').lower())\n",
    "        print('11---------------------')\n",
    "        model_predicts_scam_kline = \"yes\" in model_output.get('kline', '').lower()\n",
    "        is_correct_kline = (model_predicts_scam_kline)\n",
    "        print('12---------------------')\n",
    "        print(is_correct_kline)\n",
    "        print('12---------------------')\n",
    "        df.loc[i, '296_steps_Kline_scam'] = 1 if is_correct_kline else 0\n",
    "\n",
    "        print('21---------------------')\n",
    "        print(model_output.get('tx', '').lower())\n",
    "        print('21---------------------')\n",
    "        model_predicts_scam_tx = \"yes\" in model_output.get('tx', '').lower()\n",
    "        is_correct_tx = (model_predicts_scam_tx)\n",
    "        print('22---------------------')\n",
    "        print(is_correct_tx)\n",
    "        print('22---------------------')\n",
    "        df.loc[i, '296_steps_Tx_scam'] = 1 if is_correct_tx else 0\n",
    "        \n",
    "        print('31---------------------')\n",
    "        print(model_output.get('multimodal', '').lower())\n",
    "        print('31---------------------')\n",
    "        model_predicts_scam_multi = \"yes\" in model_output.get('multimodal', '').lower()\n",
    "        is_correct_multi = (model_predicts_scam_multi)\n",
    "        print('32---------------------')\n",
    "        print(is_correct_multi)\n",
    "        print('32---------------------')\n",
    "        df.loc[i, '296_steps_multimodal_scam'] = 1 if is_correct_multi else 0\n",
    "\n",
    "        gt_code = gt_data['code_gt']\n",
    "        model_code = model_output.get('code', 'No output found.')\n",
    "        print('41---------------------')\n",
    "        print(model_code)\n",
    "        print('41---------------------')\n",
    "        \n",
    "        api_response = deepseek_judge_match(gt_code, model_code)\n",
    "        \n",
    "        score_match = re.search(r'Score:\\s*(\\d+)', api_response, re.IGNORECASE)\n",
    "        score = int(score_match.group(1)) if score_match else 0\n",
    "        \n",
    "        is_match = score >= 50\n",
    "        print('42---------------------')\n",
    "        print(is_match)\n",
    "        print('42---------------------')\n",
    "        if i < 270:\n",
    "            df.loc[i, '296_steps_code_scam'] = 1 if is_match else 0\n",
    "        else:\n",
    "            df.loc[i, '296_steps_code_scam'] = 0 if is_match else 1\n",
    "\n",
    "    df.to_csv(file_paths[\"template_csv\"], index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nAnalysis complete! Results saved to: {file_paths['template_csv']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ecee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_KEY = \"sk-\" \n",
    "\n",
    "file_paths = {\n",
    "    \"log_file\": \"OctopusGuard/evaluations/ablation_and_training_progress/logs/analysis_log_checkpoint-0-withoutCoT.txt\",\n",
    "    \"gt_json\": \"OctopusGuard/evaluations/ablation_and_training_progress/test_multimodal_data.json\",\n",
    "    \"template_csv\": \"OctopusGuard/evaluations/ablation_and_training_progress/stepwise_template.csv\",\n",
    "}\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "api_cache = {}\n",
    "def deepseek_judge_match(gt: str, model_output: str) -> str:\n",
    "    cache_key = (gt, model_output)\n",
    "    if cache_key in api_cache:\n",
    "        return api_cache[cache_key]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "The following is the Ground Truth (human-labeled vulnerability description):\n",
    "{gt}\n",
    "\n",
    "And here is the vulnerability analysis output by the analysis tool:\n",
    "{model_output}\n",
    "\n",
    "As a blockchain security expert, please evaluate the following:\n",
    "1. Does the tool's output cover all the core issues in the Ground Truth? Summarize your judgment in one sentence (Match, Partial Match, No Match).\n",
    "2. Give a similarity score between 0 and 100 indicating how well the tool's output matches the Ground Truth. Please use the format: `Score: XX`\n",
    "\"\"\"\n",
    "    for attempt in range(3): \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "                max_tokens=256,\n",
    "                stream=False\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            api_cache[cache_key] = result\n",
    "            print(result)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"  [API Error] Attempt {attempt + 1} failed: {e}. Retrying in 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    print(f\"  [API Error] All attempts failed for GT: '{gt[:50]}...'\")\n",
    "    return \"Score: 0\" \n",
    "\n",
    "\n",
    "def parse_model_log(log_path: str) -> dict:\n",
    "    print(f\"Parsing model log file: {log_path}\")\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    results = {}\n",
    "    blocks = re.split(r'==================== Contract Address: ', content)\n",
    "    \n",
    "    for block in tqdm(blocks, desc=\"Parsing Log Blocks\"):\n",
    "        if not block.strip():\n",
    "            continue\n",
    "        \n",
    "        addr_match = re.match(r'(0x[a-fA-F0-9]{40})', block)\n",
    "        if not addr_match:\n",
    "            continue\n",
    "        address = addr_match.group(1).lower()\n",
    "\n",
    "        patterns = {\n",
    "            'kline': r\"ðŸ“ˆ \\[K-line Analysis Result\\]\\s*(.*?)\\s*(?=ðŸ“Š \\[Transaction Analysis Result\\])\",\n",
    "            'tx': r\"ðŸ“Š \\[Transaction Analysis Result\\]\\s*(.*?)\\s*(?=ðŸ§© \\[Contract Analysis Result\\])\",\n",
    "            'code': r\"ðŸ§© \\[Contract Analysis Result\\]\\s*(.*?)\\s*(?=ðŸ§  \\[Final Unified Decision\\])\",\n",
    "            'multimodal': r\"ðŸ§  \\[Final Unified Decision\\]\\s*(.*?)(?======================= ANALYSIS COMPLETE =====================)\"\n",
    "        }\n",
    "        \n",
    "        parsed_data = {}\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, block, re.DOTALL)\n",
    "            if match:\n",
    "                parsed_data[key] = match.group(1).strip()\n",
    "            else:\n",
    "                parsed_data[key] = \"\"\n",
    "        \n",
    "        results[address] = parsed_data\n",
    "    return results\n",
    "\n",
    "\n",
    "def load_ground_truth(json_path: str) -> dict:\n",
    "    print(f\"Loading ground truth from: {json_path}\")\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    gt_map = {}\n",
    "    for i in range(0, len(data), 6):\n",
    "        group = data[i:i+6]\n",
    "        if len(group) == 6:\n",
    "            gt_map[i // 6] = {\n",
    "                'kline_gt': group[0]['completion'],\n",
    "                'tx_gt': group[1]['completion'],\n",
    "                'code_gt': group[4]['completion'],\n",
    "                'multimodal_gt': group[5]['completion'], \n",
    "            }\n",
    "    return gt_map\n",
    "\n",
    "\n",
    "def is_scam_from_gt(gt_string: str, modality: str) -> bool:\n",
    "    gt_lower = gt_string.lower()\n",
    "    if modality == 'code':\n",
    "        return \"healthy\" not in gt_lower\n",
    "    else:\n",
    "        return \"scam: no\" not in gt_lower\n",
    "\n",
    "def is_scam_from_model_output(model_output_string: str, modality: str) -> bool:\n",
    "    output_lower = model_output_string.lower()\n",
    "    if modality == 'kline':\n",
    "        return output_lower.strip() != \"no\"\n",
    "    else:\n",
    "        return \"scam: no\" not in output_lower\n",
    "\n",
    "def main():\n",
    "    print(\"Starting experiment 6 analysis for checkpoint-0...\")\n",
    "    \n",
    "    df = pd.read_csv(file_paths[\"template_csv\"])\n",
    "    df['contract_address'] = df['contract_address'].str.lower()\n",
    "    \n",
    "    model_outputs = parse_model_log(file_paths[\"log_file\"])\n",
    "    ground_truths = load_ground_truth(file_paths[\"gt_json\"])\n",
    "    \n",
    "    if len(df) != len(ground_truths) or len(df) > len(model_outputs):\n",
    "         print(f\"Warning: Data length mismatch!\")\n",
    "         print(f\"CSV rows: {len(df)}, GT entries: {len(ground_truths)}, Logged addresses: {len(model_outputs)}\")\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Contracts\"):\n",
    "        address = row['contract_address']\n",
    "        \n",
    "        if i not in ground_truths:\n",
    "            print(f\"Warning: No ground truth found for index {i}, address {address}. Skipping.\")\n",
    "            continue\n",
    "        gt_data = ground_truths[i]\n",
    "\n",
    "        if address not in model_outputs:\n",
    "            print(f\"Warning: No model output found for address {address}. Skipping.\")\n",
    "            continue\n",
    "        model_output = model_outputs[address]\n",
    "\n",
    "        gt_kline_is_scam = is_scam_from_gt(gt_data['kline_gt'], 'kline')\n",
    "        model_kline_predicts_scam = is_scam_from_model_output(model_output.get('kline', ''), 'kline')\n",
    "        is_correct_kline = (model_kline_predicts_scam)\n",
    "        df.loc[i, '0_steps_Kline_scam'] = 1 if is_correct_kline else 0\n",
    "\n",
    "        gt_tx_is_scam = is_scam_from_gt(gt_data['tx_gt'], 'tx')\n",
    "        model_tx_predicts_scam = is_scam_from_model_output(model_output.get('tx', ''), 'tx')\n",
    "        is_correct_tx = (model_tx_predicts_scam)\n",
    "        df.loc[i, '0_steps_Tx_scam'] = 1 if is_correct_tx else 0\n",
    "        \n",
    "        gt_multi_is_scam = is_scam_from_gt(gt_data['multimodal_gt'], 'multimodal')\n",
    "        model_multi_predicts_scam = is_scam_from_model_output(model_output.get('multimodal', ''), 'multimodal')\n",
    "        is_correct_multi = (model_multi_predicts_scam)\n",
    "        df.loc[i, '0_steps_multimodal_scam'] = 1 if is_correct_multi else 0\n",
    "\n",
    "        gt_code = gt_data['code_gt']\n",
    "        model_code = model_output.get('code', 'No output found.')\n",
    "        \n",
    "        gt_is_healthy = not is_scam_from_gt(gt_code, 'code')\n",
    "\n",
    "        is_match_code = False\n",
    "        api_response = deepseek_judge_match(gt_code, model_code)\n",
    "        score_match = re.search(r'Score:\\s*(\\d+)', api_response, re.IGNORECASE)\n",
    "        score = int(score_match.group(1)) if score_match else 0\n",
    "        if score >= 50:\n",
    "            is_match_code = True\n",
    "        \n",
    "        if i < 270:\n",
    "            df.loc[i, '0_steps_code_scam'] = 1 if is_match_code else 0\n",
    "        else:\n",
    "            df.loc[i, '0_steps_code_scam'] = 0 if is_match_code else 1\n",
    "\n",
    "    output_path = file_paths[\"template_csv\"].replace(\".csv\", \"_results_checkpoint-0.csv\")\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nAnalysis complete! Results saved to: {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"OctopusGuard/evaluations/ablation_and_training_progress/stepwise_template.csv\")\n",
    "\n",
    "gt_column = \"scam\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if column in [\"contract_address\", gt_column]:\n",
    "        continue\n",
    "\n",
    "    y_true = df[gt_column]\n",
    "    y_pred = df[column]\n",
    "\n",
    "    tp = ((y_pred == 1) & (y_true == 1)).sum()\n",
    "    fn = ((y_pred == 0) & (y_true == 1)).sum()\n",
    "    fp = ((y_pred == 1) & (y_true == 0)).sum()\n",
    "    tn = ((y_pred == 0) & (y_true == 0)).sum()\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0.0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    print(f\"result - {column}\")\n",
    "    print(f\"TP: {tp}\")\n",
    "    print(f\"FN: {fn}\")\n",
    "    print(f\"FP: {fp}\")\n",
    "    print(f\"TN: {tn}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": column,\n",
    "        \"TP\": tp,\n",
    "        \"FN\": fn,\n",
    "        \"FP\": fp,\n",
    "        \"TN\": tn,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"stepwise_results.csv\", index=False)\n",
    "print(\"result saved to stepwise_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89295375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "steps = [\"0_steps\", \"74_steps\", \"148_steps\", \"222_steps\", \"296_steps\"]\n",
    "tasks = [\"Kline_scam\", \"Tx_scam\", \"code_scam\", \"multimodal_scam\"]\n",
    "metrics = [\"Recall\", \"Accuracy\", \"Precision\", \"F1 Score\",]\n",
    "\n",
    "df = pd.read_csv(\"stepwise_results.csv\")\n",
    "\n",
    "plot_data = {\n",
    "    metric: {task: [] for task in tasks}\n",
    "    for metric in metrics\n",
    "}\n",
    "\n",
    "for step in steps:\n",
    "    for task in tasks:\n",
    "        model_name = f\"{step}_{task}\"\n",
    "        row = df[df[\"Model\"] == model_name]\n",
    "        if not row.empty:\n",
    "            for metric in metrics:\n",
    "                value = row.iloc[0][metric]\n",
    "                plot_data[metric][task].append(value)\n",
    "        else:\n",
    "            for metric in metrics:\n",
    "                plot_data[metric][task].append(0.0)\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for task in tasks:\n",
    "        plt.plot(\n",
    "            [int(step.split(\"_\")[0]) for step in steps],\n",
    "            plot_data[metric][task],\n",
    "            marker='o',\n",
    "            label=task\n",
    "        )\n",
    "    plt.title(f\"{metric} over Steps\", fontsize=25)\n",
    "    plt.xlabel(\"Step\", fontsize=25)\n",
    "    plt.ylabel(metric, fontsize=25)\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=25)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{metric.replace(' ', '_')}_over_steps.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_ablation_log(log_path, ordered_addresses):\n",
    "    if not os.path.exists(log_path):\n",
    "        print(f\"âš ï¸ Warning: Log file not found, returning empty predictions: {log_path}\")\n",
    "        return [0] * len(ordered_addresses)\n",
    "    predictions = {}\n",
    "    current_address = None\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if \"Contract Address:\" in line:\n",
    "                match = re.search(r'Contract Address: (0x[a-fA-F0-9]{40})', line)\n",
    "                if match:\n",
    "                    current_address = match.group(1).lower()\n",
    "            if \"Final Assessment\" in line:\n",
    "                try:\n",
    "                    while True:\n",
    "                        next_line = next(f).strip()\n",
    "                        if next_line.startswith(\"Scam:\"):\n",
    "                            if \"yes\" in next_line.lower():\n",
    "                                predictions[current_address] = 1\n",
    "                            elif \"no\" in next_line.lower():\n",
    "                                predictions[current_address] = 0\n",
    "                            break\n",
    "                except StopIteration:\n",
    "                    pass\n",
    "    ordered_predictions = []\n",
    "    for addr in ordered_addresses:\n",
    "        ordered_predictions.append(predictions.get(addr.lower(), 0))\n",
    "    return ordered_predictions\n",
    "\n",
    "def analyze_ablation_study_english(csv_path, ablation_log_dir):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Main CSV file not found at {csv_path}\")\n",
    "        return\n",
    "    y_true = df['scam']\n",
    "    ordered_addresses = df['contract_address'].tolist()\n",
    "    step_to_epoch_map = {0: 0, 74: 2, 148: 4, 222: 6, 296: 8}\n",
    "    steps_list = sorted(list(step_to_epoch_map.keys()))\n",
    "    base_modalities = ['Kline', 'Tx', 'code', 'multimodal']\n",
    "    results = []\n",
    "    for step in steps_list:\n",
    "        epoch = step_to_epoch_map[step]\n",
    "        print(f\"Processing Step: {step} (Epoch: {epoch})\")\n",
    "        for modality in base_modalities:\n",
    "            col_name = f'{step}_steps_{modality}_scam'\n",
    "            if col_name not in df.columns: continue\n",
    "            y_pred = df[col_name]\n",
    "            results.append({'Step': step, 'Epoch': epoch, 'Model': modality, 'Accuracy': accuracy_score(y_true, y_pred),\n",
    "                            'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "                            'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "                            'F1-Score': f1_score(y_true, y_pred, zero_division=0)})\n",
    "        if epoch == 0:\n",
    "            print(f\"  -> Epoch 0: Using logical OR from CSV for 'Code + Tx'.\")\n",
    "            code_col, tx_col = f'{step}_steps_code_scam', f'{step}_steps_Tx_scam'\n",
    "            if code_col in df.columns and tx_col in df.columns:\n",
    "                y_pred_combined = df[code_col] | df[tx_col]\n",
    "                results.append({'Step': step, 'Epoch': epoch, 'Model': 'Code + Tx', 'Accuracy': accuracy_score(y_true, y_pred_combined),\n",
    "                                'Precision': precision_score(y_true, y_pred_combined, zero_division=0),\n",
    "                                'Recall': recall_score(y_true, y_pred_combined, zero_division=0),\n",
    "                                'F1-Score': f1_score(y_true, y_pred_combined, zero_division=0)})\n",
    "        else:\n",
    "            print(f\"  -> Epoch {epoch}: Reading 'Code + Tx' results from ablation log for step {step}.\")\n",
    "            log_file_path = os.path.join(ablation_log_dir, f\"ablation_code_tx_log_checkpoint-{step}.txt\")\n",
    "            y_pred_ablation_agent = parse_ablation_log(log_file_path, ordered_addresses)\n",
    "            if len(y_pred_ablation_agent) != len(y_true):\n",
    "                print(f\"âŒ Error: Mismatch in prediction count for step {step}. Expected {len(y_true)}, got {len(y_pred_ablation_agent)}\")\n",
    "                continue\n",
    "            results.append({'Step': step, 'Epoch': epoch, 'Model': 'Code + Tx', 'Accuracy': accuracy_score(y_true, y_pred_ablation_agent),\n",
    "                            'Precision': precision_score(y_true, y_pred_ablation_agent, zero_division=0),\n",
    "                            'Recall': recall_score(y_true, y_pred_ablation_agent, zero_division=0),\n",
    "                            'F1-Score': f1_score(y_true, y_pred_ablation_agent, zero_division=0)})\n",
    "    results_df = pd.DataFrame(results)\n",
    "    plot_performance_curves_final(results_df)\n",
    "\n",
    "\n",
    "def plot_performance_curves_final(results_df):\n",
    "    if results_df.empty:\n",
    "        print(\"No data available for plotting.\")\n",
    "        return\n",
    "        \n",
    "    model_order = ['code', 'Tx', 'Code + Tx', 'Kline', 'multimodal']\n",
    "    results_df['Model'] = pd.Categorical(results_df['Model'], categories=model_order, ordered=True)\n",
    "    results_df = results_df.sort_values('Model')\n",
    "\n",
    "    FIG_SIZE = (22, 20) \n",
    "    FONT_SIZE = 30 \n",
    "    LABEL_PAD = 20 \n",
    "    TICK_PAD = 15  \n",
    "    LINE_WIDTH, MARKER_SIZE = 3.0, 10.0\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=FIG_SIZE)\n",
    "    \n",
    "    metrics_to_plot = ['F1-Score', 'Recall', 'Precision', 'Accuracy']\n",
    "    palette = sns.color_palette(\"bright\", n_colors=len(results_df['Model'].unique()))\n",
    "\n",
    "    for ax, metric in zip(axes.flatten(), metrics_to_plot):\n",
    "        sns.lineplot(\n",
    "            data=results_df, x='Epoch', y=metric, hue='Model', style='Model', \n",
    "            markers=True, dashes=True, ax=ax, palette=palette,\n",
    "            linewidth=LINE_WIDTH, markersize=MARKER_SIZE\n",
    "        )\n",
    "        \n",
    "        ax.set_ylabel(metric, fontsize=FONT_SIZE, labelpad=LABEL_PAD)\n",
    "        ax.set_xlabel('Epoch', fontsize=FONT_SIZE, labelpad=LABEL_PAD)\n",
    "\n",
    "        ax.grid(True, linestyle='--', alpha=0.7, linewidth=1.0)\n",
    "        \n",
    "        legend = ax.legend(\n",
    "            title='Model',\n",
    "            title_fontsize=FONT_SIZE, \n",
    "            fontsize=FONT_SIZE,      \n",
    "            loc='best'                \n",
    "        )\n",
    "        for leg_line in legend.get_lines():\n",
    "            leg_line.set_linewidth(3.0)\n",
    "            \n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE, pad=TICK_PAD)\n",
    "        ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "\n",
    "    plt.tight_layout(pad=2.0)\n",
    "    plt.savefig(\"ablation_study_epochs_all_legends.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main_csv_file = 'stepwise_results.csv'\n",
    "    ablation_log_directory = 'OctopusGuard/evaluations/ablation_and_training_progress/logs'\n",
    "    \n",
    "    analyze_ablation_study_english(main_csv_file, ablation_log_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resnet18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
