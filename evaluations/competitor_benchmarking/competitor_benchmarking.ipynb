{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_path = \"OctopusGuard/data/experiment_address.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "df[\"scam\"] = 1\n",
    "df.loc[df.index[-30:], \"scam\"] = 0\n",
    "\n",
    "models = [\"smartinv\", \"SmarTest\", \"verismart\", \"honeypot_is\", \"slither\", \"ours\"]\n",
    "tasks = [\"scam\"]\n",
    "\n",
    "for model in models:\n",
    "    for task in tasks:\n",
    "        df[f\"{model}_{task}\"] = None \n",
    "\n",
    "output_path = \"OctopusGuard/evaluations/competitor_benchmarking/competitor_benchmarking_template.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"success: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e415b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-\",  \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "def deepseek_judge_match(gt: str, slither_output: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "The following is the Ground Truth (human-labeled vulnerability description):\n",
    "{gt}\n",
    "\n",
    "And here is the vulnerability analysis output by the Slither tool:\n",
    "{slither_output}\n",
    "\n",
    "As a blockchain security expert, please evaluate the following:\n",
    "1. Does the Slither output cover all the core issues in the Ground Truth? Summarize your judgment in one sentence (Match, Partial Match, No Match).\n",
    "2. Give a similarity score between 0 and 100 indicating how well Slither's output matches the Ground Truth. Please use the format: `Score: XX`\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "        max_tokens=256,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def extract_ground_truths(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    ground_truths = []\n",
    "    for i in range(0, 300 * 6, 6):\n",
    "        sample_group = data[i:i+6]\n",
    "        ground_truth = sample_group[4]['completion']\n",
    "        ground_truths.append(ground_truth.strip())\n",
    "    return ground_truths\n",
    "\n",
    "def extract_slither_reports(log_path):\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    reports = re.split(r\"======= Analyzing contract: .+? =======\\s*\", content)[1:]\n",
    "    return [report.strip() for report in reports[:300]] \n",
    "\n",
    "def parse_score(response_text: str) -> int:\n",
    "    match = re.search(r\"Score:\\s*(\\d{1,3})\", response_text)\n",
    "    if match:\n",
    "        score = int(match.group(1))\n",
    "        return max(0, min(100, score))  \n",
    "    return 0  \n",
    "\n",
    "def main():\n",
    "    json_path = \"OctopusGuard/data/test_multimodal_data.json\"\n",
    "    log_path = \"OctopusGuard/evaluations/competitor_benchmarking/combined_slither_report.txt\"\n",
    "    csv_path = \"OctopusGuard/evaluations/competitor_benchmarking/competitor_benchmarking_template.csv\"\n",
    "    output_log_path = \"deepseek_eval_log_slither.txt\"\n",
    "\n",
    "    ground_truths = extract_ground_truths(json_path)\n",
    "    slither_outputs = extract_slither_reports(log_path)\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    slither_scam_results = []\n",
    "\n",
    "    with open(output_log_path, \"w\", encoding=\"utf-8\") as logfile:\n",
    "        for idx, (gt, slither_report) in enumerate(zip(ground_truths, slither_outputs)):\n",
    "            print(f\"\\n===== Contract {idx+1} =====\")\n",
    "            logfile.write(f\"\\n===== Contract {idx+1} =====\\n\")\n",
    "            logfile.flush()\n",
    "            try:\n",
    "                reply = deepseek_judge_match(gt, slither_report)\n",
    "                print(reply)\n",
    "                logfile.write(reply + \"\\n\")\n",
    "                logfile.flush()\n",
    "\n",
    "                score = parse_score(reply)\n",
    "                print(f\"[Score Parsed]: {score}\")\n",
    "                logfile.write(f\"[Score Parsed]: {score}\\n\")\n",
    "\n",
    "                if idx < 270:\n",
    "                    scam = 1 if score >= 50 else 0\n",
    "                else:\n",
    "                    scam = 0 if score >= 50 else 1\n",
    "\n",
    "                slither_scam_results.append(scam)\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = f\"[ERROR] Contract {idx+1} failed: {e}\"\n",
    "                print(error_msg)\n",
    "                logfile.write(error_msg + \"\\n\")\n",
    "                logfile.flush()\n",
    "                slither_scam_results.append(0)  \n",
    "\n",
    "    df['slither_scam'] = slither_scam_results\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-\",  \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "def deepseek_judge_match(gt: str, slither_output: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "The following is the Ground Truth (human-labeled vulnerability description):\n",
    "{gt}\n",
    "\n",
    "And here is the vulnerability analysis output by the VeriSmart tool:\n",
    "{slither_output}\n",
    "\n",
    "As a blockchain security expert, please evaluate the following:\n",
    "1. Does the Slither output cover all the core issues in the Ground Truth? Summarize your judgment in one sentence (Match, Partial Match, No Match).\n",
    "2. Give a similarity score between 0 and 100 indicating how well Slither's output matches the Ground Truth. Please use the format: `Score: XX`\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "        max_tokens=256,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def parse_score(response_text: str) -> int:\n",
    "    match = re.search(r\"Score:\\s*(\\d{1,3})\", response_text)\n",
    "    if match:\n",
    "        score = int(match.group(1))\n",
    "        return max(0, min(100, score))  \n",
    "    return 0  \n",
    "\n",
    "def extract_ground_truths(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    ground_truths = []\n",
    "    for i in range(0, 300 * 6, 6):\n",
    "        sample_group = data[i:i+6]\n",
    "        ground_truth = sample_group[4]['completion']\n",
    "        ground_truths.append(ground_truth.strip())\n",
    "    return ground_truths\n",
    "\n",
    "def load_contract_addresses(csv_path):\n",
    "    addresses = []\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            addr = row.get(\"contract_address\")\n",
    "            if addr:\n",
    "                addresses.append(addr.strip())\n",
    "    return addresses[:300]  \n",
    "\n",
    "def load_verismart_logs(log_dir, addresses):\n",
    "    logs = []\n",
    "    for addr in addresses:\n",
    "        filename = os.path.join(log_dir, f\"{addr}_verify.log\")\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "                logs.append(f.read().strip())\n",
    "        else:\n",
    "            logs.append(\"[LOG NOT FOUND]\")\n",
    "    return logs\n",
    "\n",
    "def main():\n",
    "    json_path = \"OctopusGuard/data/test_multimodal_data.json\"\n",
    "    log_dir = \"OctopusGuard/evaluations/competitor_benchmarking/versmart_logs\"\n",
    "    addr_csv_path = \"OctopusGuard/evaluations/competitor_benchmarking/competitor_benchmarking_template.csv\"\n",
    "    output_log_path = \"deepseek_eval_log_verismart.txt\"\n",
    "\n",
    "    ground_truths = extract_ground_truths(json_path)\n",
    "    addresses = load_contract_addresses(addr_csv_path)\n",
    "    verismart_logs = load_verismart_logs(log_dir, addresses)\n",
    "\n",
    "    df = pd.read_csv(addr_csv_path)\n",
    "    scam_results = []\n",
    "\n",
    "    with open(output_log_path, \"w\", encoding=\"utf-8\") as logfile:\n",
    "        for idx, (gt, verilog) in enumerate(zip(ground_truths, verismart_logs)):\n",
    "            print(f\"\\n===== Contract {idx+1} Deepseek Response (VeriSmart) =====\")\n",
    "            logfile.write(f\"\\n===== Contract {idx+1} Deepseek Response (VeriSmart) =====\\n\")\n",
    "            logfile.flush()\n",
    "            try:\n",
    "                reply = deepseek_judge_match(gt, verilog)\n",
    "                print(reply)\n",
    "                logfile.write(reply + \"\\n\")\n",
    "                logfile.flush()\n",
    "\n",
    "                score = parse_score(reply)\n",
    "                print(f\"[Score Parsed]: {score}\")\n",
    "                logfile.write(f\"[Score Parsed]: {score}\\n\")\n",
    "\n",
    "                if idx < 270:  \n",
    "                    scam = 1 if score >= 50 else 0\n",
    "                else:  \n",
    "                    scam = 0 if score >= 50 else 1\n",
    "\n",
    "                scam_results.append(scam)\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = f\"[ERROR] Contract {idx+1} failed: {e}\"\n",
    "                print(error_msg)\n",
    "                logfile.write(error_msg + \"\\n\")\n",
    "                logfile.flush()\n",
    "                scam_results.append(0)  \n",
    "\n",
    "    df = df[:300]  \n",
    "    df['verismart_scam'] = scam_results\n",
    "    df.to_csv(addr_csv_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c08f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-\",  # Replace with your Deepseek API Key\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "def deepseek_judge_match(gt: str, slither_output: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "The following is the Ground Truth (human-labeled vulnerability description):\n",
    "{gt}\n",
    "\n",
    "And here is the vulnerability analysis output by the SmarTest tool:\n",
    "{slither_output}\n",
    "\n",
    "As a blockchain security expert, please evaluate the following:\n",
    "1. Does the Slither output cover all the core issues in the Ground Truth? Summarize your judgment in one sentence (Match, Partial Match, No Match).\n",
    "2. Give a similarity score between 0 and 100 indicating how well Slither's output matches the Ground Truth. Please use the format: `Score: XX`\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "        max_tokens=256,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def parse_score(response_text: str) -> int:\n",
    "    match = re.search(r\"Score:\\s*(\\d{1,3})\", response_text)\n",
    "    if match:\n",
    "        score = int(match.group(1))\n",
    "        return max(0, min(100, score))  \n",
    "    return 0  \n",
    "\n",
    "def extract_ground_truths(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    ground_truths = []\n",
    "    for i in range(0, 300 * 6, 6):\n",
    "        sample_group = data[i:i+6]\n",
    "        ground_truth = sample_group[4]['completion']\n",
    "        ground_truths.append(ground_truth.strip())\n",
    "    return ground_truths\n",
    "\n",
    "def load_contract_addresses(csv_path):\n",
    "    addresses = []\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            addr = row.get(\"contract_address\")\n",
    "            if addr:\n",
    "                addresses.append(addr.strip())\n",
    "    return addresses[:300]  \n",
    "\n",
    "def load_verismart_logs(log_dir, addresses):\n",
    "    logs = []\n",
    "    for addr in addresses:\n",
    "        filename = os.path.join(log_dir, f\"{addr}_exploit.log\")\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "                logs.append(f.read().strip())\n",
    "        else:\n",
    "            logs.append(\"[LOG NOT FOUND]\")\n",
    "    return logs\n",
    "\n",
    "def main():\n",
    "    json_path = \"OctopusGuard/data/test_multimodal_data.json\"\n",
    "    log_dir = \"OctopusGuard/evaluations/competitor_benchmarking/versmart_logs\"\n",
    "    addr_csv_path = \"OctopusGuard/evaluations/competitor_benchmarking/competitor_benchmarking_template.csv\"\n",
    "    output_log_path = \"deepseek_eval_log_smartest.txt\"\n",
    "\n",
    "    ground_truths = extract_ground_truths(json_path)\n",
    "    addresses = load_contract_addresses(addr_csv_path)\n",
    "    verismart_logs = load_verismart_logs(log_dir, addresses)\n",
    "\n",
    "    df = pd.read_csv(addr_csv_path)\n",
    "    scam_results = []\n",
    "\n",
    "    with open(output_log_path, \"w\", encoding=\"utf-8\") as logfile:\n",
    "        for idx, (gt, verilog) in enumerate(zip(ground_truths, verismart_logs)):\n",
    "            print(f\"\\n===== Contract {idx+1} Deepseek Response (SmarTest) =====\")\n",
    "            logfile.write(f\"\\n===== Contract {idx+1} Deepseek Response (SmarTest) =====\\n\")\n",
    "            logfile.flush()\n",
    "            try:\n",
    "                reply = deepseek_judge_match(gt, verilog)\n",
    "                print(reply)\n",
    "                logfile.write(reply + \"\\n\")\n",
    "                logfile.flush()\n",
    "\n",
    "                score = parse_score(reply)\n",
    "                print(f\"[Score Parsed]: {score}\")\n",
    "                logfile.write(f\"[Score Parsed]: {score}\\n\")\n",
    "\n",
    "                if idx < 270:\n",
    "                    scam = 1 if score >= 50 else 0\n",
    "                else:\n",
    "                    scam = 0 if score >= 50 else 1\n",
    "\n",
    "                scam_results.append(scam)\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = f\"[ERROR] Contract {idx+1} failed: {e}\"\n",
    "                print(error_msg)\n",
    "                logfile.write(error_msg + \"\\n\")\n",
    "                logfile.flush()\n",
    "                scam_results.append(0) \n",
    "\n",
    "    df = df[:300]  \n",
    "    df['smartest_scam'] = scam_results\n",
    "    df.to_csv(addr_csv_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-\", \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "def deepseek_judge_match(gt: str, slither_output: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "The following is the Ground Truth (human-labeled vulnerability description):\n",
    "{gt}\n",
    "\n",
    "And here is the vulnerability analysis output by the smartInv tool:\n",
    "{slither_output}\n",
    "\n",
    "As a blockchain security expert, please evaluate the following:\n",
    "1. Does the smartInv output cover all the core issues in the Ground Truth? Summarize your judgment in one sentence (Match, Partial Match, No Match).\n",
    "2. Give a similarity score between 0 and 100 indicating how well smartInv's output matches the Ground Truth. Please use the format: `Score: XX`\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "        max_tokens=256,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def extract_ground_truths(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    ground_truths = []\n",
    "    for i in range(0, 300 * 6, 6):\n",
    "        sample_group = data[i:i+6]\n",
    "        ground_truth = sample_group[4]['completion']\n",
    "        ground_truths.append(ground_truth.strip())\n",
    "    return ground_truths\n",
    "\n",
    "def extract_slither_reports(log_path):\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"==================== Contract Address:.*?\\n(.*?)\\n====================== ANALYSIS COMPLETE =====================\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "    \n",
    "    reports = pattern.findall(content)\n",
    "    \n",
    "    return [report.strip() for report in reports[:781]]\n",
    "\n",
    "def parse_score(response_text: str) -> int:\n",
    "    match = re.search(r\"Score:\\s*(\\d{1,3})\", response_text)\n",
    "    if match:\n",
    "        score = int(match.group(1))\n",
    "        return max(0, min(100, score)) \n",
    "    return 0  \n",
    "\n",
    "def main():\n",
    "    json_path = \"OctopusGuard/data/test_multimodal_data.json\"\n",
    "    log_path = \"OctopusGuard/evaluations/competitor_benchmarking/analysis_log_samrtInv.txt\"\n",
    "    csv_path = \"OctopusGuard/evaluations/competitor_benchmarking/competitor_benchmarking_template.csv\"\n",
    "    output_log_path = \"deepseek_eval_log_smartInv.txt\"\n",
    "\n",
    "    ground_truths = extract_ground_truths(json_path)\n",
    "    slither_outputs = extract_slither_reports(log_path)\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    slither_scam_results = []\n",
    "\n",
    "    with open(output_log_path, \"w\", encoding=\"utf-8\") as logfile:\n",
    "        for idx, (gt, slither_report) in enumerate(zip(ground_truths, slither_outputs)):\n",
    "            print(f\"\\n===== Contract {idx+1} =====\")\n",
    "            logfile.write(f\"\\n===== Contract {idx+1} =====\\n\")\n",
    "            logfile.flush()\n",
    "            try:\n",
    "                reply = deepseek_judge_match(gt, slither_report)\n",
    "                print(reply)\n",
    "                logfile.write(reply + \"\\n\")\n",
    "                logfile.flush()\n",
    "\n",
    "                score = parse_score(reply)\n",
    "                print(f\"[Score Parsed]: {score}\")\n",
    "                logfile.write(f\"[Score Parsed]: {score}\\n\")\n",
    "\n",
    "                if idx < 270:\n",
    "                    scam = 1 if score >= 50 else 0\n",
    "                else:\n",
    "                    scam = 0 if score >= 50 else 1\n",
    "\n",
    "                slither_scam_results.append(scam)\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = f\"[ERROR] Contract {idx+1} failed: {e}\"\n",
    "                print(error_msg)\n",
    "                logfile.write(error_msg + \"\\n\")\n",
    "                logfile.flush()\n",
    "                slither_scam_results.append(0) \n",
    "\n",
    "    df['smartInv_scam'] = slither_scam_results\n",
    "    df.to_csv(csv_path, index=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "input_csv_path = \"OctopusGuard/evaluations/competitor_benchmarking/competitor_benchmarking_template.csv\"\n",
    "log_file_path = \"OctopusGuard/evaluations/competitor_benchmarking/honeypotIs_api_log.txt\"\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "if 'honeypot_is_scam' not in df.columns:\n",
    "    df['honeypot_is_scam'] = ''\n",
    "\n",
    "with open(log_file_path, 'a', encoding='utf-8') as log_file:\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        address = row['contract_address']\n",
    "\n",
    "        current_value = str(row['honeypot_is_scam']).strip()\n",
    "        if current_value in ['0', '1']:\n",
    "            continue\n",
    "\n",
    "        print(f\" {address}...\")\n",
    "\n",
    "        url = \"https://api.honeypot.is/v2/IsHoneypot\"\n",
    "        params = {'address': address}\n",
    "\n",
    "        retry_count = 0\n",
    "        max_retries = 20\n",
    "\n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                response = requests.get(url, params=params, timeout=30)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "\n",
    "                is_honeypot = data.get('honeypotResult', {}).get('isHoneypot', None)\n",
    "\n",
    "                if is_honeypot is True:\n",
    "                    df.at[idx, 'honeypot_is_scam'] = 1\n",
    "                elif is_honeypot is False:\n",
    "                    df.at[idx, 'honeypot_is_scam'] = 0\n",
    "                else:\n",
    "                    df.at[idx, 'honeypot_is_scam'] = ''\n",
    "\n",
    "                log_file.write(f\"address: {address}\\n\")\n",
    "                log_file.write(json.dumps(data, ensure_ascii=False, indent=4))\n",
    "                log_file.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "                log_file.flush()\n",
    "\n",
    "                break  \n",
    "\n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                print(f\"failed ({retry_count}/20): {str(e)}ï¼Œretrying...\")\n",
    "                time.sleep(3)\n",
    "\n",
    "        if retry_count >= max_retries:\n",
    "            print(f\"{address} no liquidity pool\")\n",
    "            df.at[idx, 'honeypot_is_scam'] = 0\n",
    "\n",
    "        time.sleep(1)  \n",
    "\n",
    "df['honeypot_is_scam'] = pd.to_numeric(df['honeypot_is_scam'], errors='coerce').astype('Int64')\n",
    "df.to_csv(input_csv_path, index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ab720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "df = pd.read_csv(\"OctopusGuard/evaluations/competitor_benchmarking/competitor_benchmarking_template.csv\")  \n",
    "\n",
    "y_true = df[\"scam\"]\n",
    "\n",
    "tools = [col for col in df.columns if col not in [\"contract_address\", \"scam\"]]\n",
    "\n",
    "results = []\n",
    "\n",
    "for tool in tools:\n",
    "    y_pred = df[tool]\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"result - {tool}\")\n",
    "    print(f\"TP: {tp}\")\n",
    "    print(f\"FN: {fn}\")\n",
    "    print(f\"FP: {fp}\")\n",
    "    print(f\"TN: {tn}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    results.append({\n",
    "        \"Tool\": tool,\n",
    "        \"TP\": tp,\n",
    "        \"FN\": fn,\n",
    "        \"FP\": fp,\n",
    "        \"TN\": tn,\n",
    "        \"Precision\": round(precision, 4),\n",
    "        \"Recall\": round(recall, 4),\n",
    "        \"Accuracy\": round(accuracy, 4),\n",
    "        \"F1 Score\": round(f1, 4)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"competitor_benchmarking_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resnet18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
